'''
–£–∂ –µ—Å–ª–∏ —Ç—ã –∏ —é–Ω—ã–π –ø–∞—Å—Ç–µ—Ä–æ–∫ , —Ç–æ —Ö–æ—Ç—è –±—ã –∏—Å—Ç–æ—á–Ω–∏–∫ —É–∫–∞–∑—ã–≤–∞–π –æ—Ç–∫—É–¥–∞ –ø–∞—Å—Ç–∏–ª :)
–í —Ç–≤–æ–µ–º —Å–ª—É—á–∞–µ: @KangelPlugins 
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ö‚†Å‚£Ä‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚°¥‚†∂‚£æ‚†û‚¢Å‚£Ä‚£†‚†§‚†§‚¢§‚£Ä‚£Ä‚°Ä‚†Ä‚†Ä‚¢∞‚°ñ‚†í‚†≤‚¢¶‚£å‚°≥‚£ø‚¢•‚°Ä‚†à‚¢ª‚£∂‚°é‚†Ä‚†Ä‚¢Ä‚£¥‚†ü‚†â‚†Ä‚¢†‚°ü‚†Ä‚†Ä‚†Ä‚†Ä‚¢†‚°ü‚†Ä‚£æ‚†Ä‚†Ä
‚£¶‚£º‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£∏‚£ø‚†Ä‚†Ä‚†Ä‚¢Ä‚°§‚†ö‚†Å‚†Ä‚£º‚†Å‚°¥‚†ã‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚†ô‚†≥‚¢æ‚£á‚†Ä‚°Ä‚†Ü‚£π‚£§‚°à‚†Ä‚°á‚†Ä‚†Ä‚†â‚°á‚†Ä‚¢†‚†ü‚†É‚†Ä‚†Ä‚†Ä‚¢∏‚†á‚†Ä‚†Ä‚†Ä‚†Ä‚£º‚†Å‚¢†‚°Ø‚†§‚†¥
‚†à‚†ª‚£ø‚£Ç‚£Ä‚£†‚£æ‚†ü‚¢ª‚£ø‚£∑‚£Ä‚°∂‚†ã‚†Ä‚†Ä‚†Ä‚†Ä‚£ª‚°¶‚†ì‚†Ä‚†Ä‚¢∞‚£û‚†ª‚£ç‚†ô‚†≤‚¢§‚£Ä‚†Ä‚£†‚†û‚†í‚†õ‚†â‚†Å‚†à‚†ª‚£ç‚†â‚†≥‚†§‚£§‚£á‚°¥‚†ã‚†Ä‚†Ä‚£Ä‚£§‚£∂‚¢æ‚†Ä‚†Ä‚†Ä‚†Ä‚¢∞‚°á‚†Ä‚¢∏‚£ß‚†Ä‚†Ä
‚†Ä‚†Ä‚†à‚†ª‚£ø‚†ü‚†Å‚†Ä‚†Ä‚¢ø‚£ø‚†è‚†Ä‚†Ä‚†Ä‚¢Ä‚°¥‚†ã‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚¢¶‚°à‚†ì‚¢¶‚£Ä‚£à‚†ô‚†≥‚†∂‚†∂‚£∂‚£í‚°≤‚£Ü‚†Ä‚†ò‚¢ß‚°Ä‚†Ä‚†à‚¢Ø‚£†‚†∂‚£§‚£æ‚£ø‚£ø‚£ø‚¢∏‚†Ä‚†Ä‚†Ä‚†Ä‚£æ‚†Ä‚†Ä‚°ü‚£ø‚£∂‚£∂
‚†Ä‚†Ä‚†Ä‚£∞‚†è‚†Ä‚†Ä‚†Ä‚†Ä‚†∏‚°á‚†Ä‚†Ä‚†Ä‚°¥‚†ã‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚†∂‚£§‚°Ä‚†â‚†ì‚†¶‚£§‚£Ä‚†Ä‚†à‚†â‚¢ª‚°Ü‚†Ä‚†Ä‚†≥‚£Ñ‚£†‚£∂‚£Ö‚£Ä‚°à‚¢ø‚£ø‚£ø‚£ø‚¢∏‚£Ä‚°Ä‚†Ä‚¢†‚°ü‚†Ä‚†Ä‚°á‚£ø‚£ø‚£ø
‚†Ä‚†Ä‚¢†‚°è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢≥‚†Ä‚¢Ä‚°æ‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£§‚°§‚†§‚†§‚†§‚†§‚†§‚†Ω‚†∂‚¢§‚£§‚°Ñ‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Å‚†Ä‚†Ä‚†Ä‚†à‚£ø‚†Ä‚†à‚£ø‚£ø‚†ô‚£ø‚£ø‚£è‚†â‚†â‚†â‚†ì‚†æ‚¢ß‚£Ñ‚£Ä‚£ø‚£ø‚£ø‚£ø
‚†Ä‚†Ä‚¢∏‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚°Ü‚£º‚†Å‚†Ä‚†Ä‚†Ä‚¢†‚†Ü‚†Ä‚£æ‚†ò‚†ß‚†§‚£Ñ‚£Ä‚£Ä‚£Ä‚£Ä‚£Ä‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£Ä‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢†‚†á‚†Ä‚†Ä‚†Ä‚°Ø‚†Ä‚†ª‚°á‚†à‚£ø‚£¶‚°Ä‚¢Ä‚†Ä‚†Ä‚†à‚†â‚†ô‚†ª‚†≠‚£Ω
‚£¢‚£Ñ‚°à‚¢ß‚†Ä‚†≥‚£Ñ‚†Ä‚†Ä‚†Ä‚†à‚£∑‚°è‚†Ä‚†Ä‚†Ä‚¢Ä‚°ü‚†Ä‚¢Ä‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚†à‚†â‚†ô‚†í‚¢¶‚°¥‚†ü‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚††‚°æ‚†Ä‚†à‚££‚£¥‚†ó‚¢¶‚¢Ä‚°ø‚°Ñ‚°á‚†π‚°é‚†≤‚£ï‚¢Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†à‚†ô‚¢ø‚£Æ‚£≥‚°Ä‚†∏‚°Ü‚†Ä‚†Ä‚¢Ä‚£ª‚†É‚†Ä‚†Ä‚†Ä‚¢∏‚†É‚†Ä‚¢∏‚†Ä‚†Ä‚†Ä‚†Ä‚°Ä‚†Ä‚†Ä‚¢Ä‚£¨‚†∑‚†§‚†§‚†ñ‚†ã‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£Ä‚£§‚£§‚£¥‚°á‚†Ä‚¢∞‚£ø‚°ü‚†Ä‚£º‚¢ø‚†Å‚†Ä‚°á‚†Ä‚¢≥‚†Ä‚†à‚¢¶‚°Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚¢ô‚°ø‚¢ø‚£¶‚£ø‚†Ä‚†Ä‚£º‚¢∏‚†Ä‚†Ä‚†Ä‚†ê‚°ü‚†Ä‚†Ä‚°ü‚†Ä‚†Ä‚†Ä‚†Ä‚£ß‚†Ä‚†∞‚£è‚£Ä‚£Ä‚£Ä‚£Ä‚£Ä‚£Ä‚°§‚†§‚†ñ‚†í‚†ö‚¢π‚£ø‚†õ‚£ü‚°Ä‚¢†‚£ø‚°ø‚†Å‚£º‚£∑‚°ø‚†Ä‚¢Ä‚°ß‚†Ä‚†ò‚°Ü‚†Ä‚†Ä‚†ô‚†Ü‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚£†‚†é‚¢Ä‚°Ä‚£ø‚¢ø‚£á‚£∞‚†á‚¢∏‚†Ä‚¢∏‚†Ä‚¢∞‚†á‚†Ä‚†Ä‚°á‚†Ä‚†Ä‚†Ä‚¢†‚†ø‚£á‚¢ª‚°Ñ‚†Ä‚†Ä‚†Ä‚†ô‚¢¶‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚†ü‚†â‚¢¶‚°à‚¢ª‚†õ‚†ª‚¢ß‚£¥‚£ø‚°ø‚†Å‚†Ä‚£æ‚†Å‚†Ä‚†Ä‚£∑‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚¢à‚°µ‚¢Ä‚†û‚£†‚£ø‚¢à‚£ø‚†è‚†Ä‚£è‚†Ä‚¢∏‚†Ä‚¢∏‚†Ä‚†Ä‚††‚°ß‚†§‚†§‚£Ä‚£∏‚°Ä‚†ò‚¢¶‚°ª‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚¢∑‚£¶‚£Ñ‚°ò‚†Å‚†Ä‚†Ä‚†Ä‚†≥‚£¨‚£á‚†Ä‚†à‚£Ø‚†â‚†ì‚†¶‚£º‚†ã‚†Ä‚†Ä‚†Ä‚¢π‚†Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ñ‚£π‚£†‚°è‚°Ä‚¢à‚£ø‚°ø‚†Å‚†Ä‚£∏‚†è‚†Ä‚¢∏‚°Ä‚¢∏‚†Ä‚†Ä‚†Ä‚£∑‚†Ä‚†Ä‚†Ä‚¢∏‚†â‚†ô‚†¶‚¢ù‚£æ‚£¶‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚†≤‚¢ç‚†õ‚†≤‚¢§‚£Ä‚£Ä‚°Ω‚£ø‚°§‚†∂‚¢ø‚°Ü‚†Ä‚£†‚¢ø‚†Ä‚†Ä‚†Ä‚†Ä‚†∏‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚£∂‚†æ‚†ø‚¢¥‚£∑‚°ø‚†ã‚†Ä‚†Ä‚¢†‚£ø‚†Ä‚†Ä‚¢∏‚£á‚¢∏‚°Ñ‚†Ä‚†Ä‚°ø‚£á‚†Ä‚†Ä‚¢∏‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚†ø‚£ß‚°Ä‚†Ä‚¢Ä‚¢Ä‚£§‚†¥‚†õ‚†Ä‚†Ä‚†Ä‚¢Ä‚°¥‚†ñ‚†Ä‚†Ä‚¢Ä‚£ø‚°ü‚†Å‚£∏‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†ª‚£ø‚£Ñ‚°æ‚†ã‚†Ä‚†Ä‚†Ä‚¢†‚°û‚£ª‚°Ä‚†Ä‚¢∏‚¢ª‚°Ñ‚¢≥‚°Ä‚†Ä‚¢∑‚£∏‚¢¶‚†Ä‚†∫‚£Ñ‚°Ä‚¢Ä‚£Ä‚£Ä‚†Ä‚†Ä‚†Ä‚†ô‚†ì‚†ü‚†ã‚†Å‚†Ä‚†Ä‚†Ä‚¢Ä‚°¥‚£´‚£§‚£∂‚£∂‚£ñ‚£π‚¢ø‚£ß‚†Ä‚†∏‚£Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚£†‚†û‚†ã‚†Ä‚†Ä‚†Ä‚†Ä‚¢†‚£ø‚†Ä‚†∏‚£ß‚†Ä‚¢∏‚°å‚¢∑‚°à‚¢∑‚°Ä‚†∏‚£ø‚£∑‚£∑‚£§‚¢ø‚°ø‚¢ø‚£ø‚†æ‚£ø‚£Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£æ‚°ø‚†õ‚†Å‚†Ä‚†Ä‚†Ä‚£ø‚£ø‚£ø‚°á‚†Ä‚†ô‚†õ‚¢ª‚†õ‚†õ‚£ª‚°ó‚†í‚†ö‚†õ‚†≤‚†§‚£§
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£¥‚£ø‚£ø‚£ß‚†Ä‚†π‚°Ü‚†∏‚£ß‚†à‚¢≥‚°à‚¢∑‚°Ä‚¢ø‚°ü‚¢ª‚°É‚£∏‚£ø‚†Ä‚¢ª‚°á‚†à‚†è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†∏‚†É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚£ø‚£ø‚£ø‚£ø‚†Ä‚†Ä‚†Ä‚¢∏‚†Ä‚¢Ä‚°è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚¢Ä‚°¥‚†ª‚£ø‚£ø‚£ø‚£ø‚£∑‚£Ñ‚†ô‚£¶‚£ø‚£ß‚†à‚¢≥‚°Ä‚¢≥‚£ú‚£∑‚°ò‚£∑‚£Æ‚£Å‚£Ä‚£∏‚†á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚£å‚£ø‚£ü‚£ø‚†Ä‚†Ä‚¢∏‚¢∏‚†ì‚£æ‚°É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚¢Ä‚°¥‚†ã‚†Ä‚†±‚¢Æ‚£ª‚£ø‚£ø‚£ø‚£ø‚£∂‚£å‚°π‚£ü‚£∑‚°Ñ‚†ô‚¢Æ‚°è‚†ª‚£∑‚°¨‚¢ø‚°ø‚¢ø‚°µ‚†û‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚°Ö‚†Ä‚¢ª‚£æ‚†Ä‚†Ä‚¢∏‚¢∏‚†Ä‚†à‚¢ª‚°Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚£¥‚°ø‚£¶‚°Ñ‚†Ä‚†Ä‚†Ä‚¢ª‚£ª‚£ø‚£ü‚¢ª‚†õ‚£ø‚£ª‚£ø‚£è‚¢ø‚†∂‚£Ñ‚†ô‚¢¶‚°à‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ê‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢†‚£ø‚†Ä‚†Ä‚†à‚£ø‚†Ä‚†Ä‚¢∏‚¢∏‚†Ä‚†Ä‚¢∏‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚£ø‚£¶‚£æ‚£ø‚£Ü‚†Ä‚†Ä‚†Ä‚°è‚£ø‚£ø‚£∑‚£ø‚£ø‚£ø‚†ø‚£ü‚†æ‚£ß‚†à‚†ª‚£¶‚£ù‚£¶‚£Ñ‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£Ä‚£Ä‚£Ä‚£Ä‚£Ä‚£Ä‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚†ü‚£ø‚£Ä‚†Ä‚†Ä‚¢∏‚†Ä‚†Ä‚£∏‚¢∏‚°Ä‚†Ä‚£∏‚†É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†æ‚†ø‚†ø‚†ø‚£ø‚°Ñ‚†Ä‚¢Ä‚£∏‚£º‚†ø‚†ø‚¢õ‚†õ‚†Å‚†Ä‚†à‚†≥‚£ø‚£ß‚†Ä‚†ª‚£¶‚°â‚†õ‚†ø‚¢∂‚£¶‚£§‚†Ä‚†Ä‚†Ä‚£ø‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚¢ª‚°á‚†Ä‚†Ä‚£†‚£æ‚£ø‚°Ñ‚¢∏‚†∏‚°Ñ‚†Ä‚¢∏‚†Ä‚¢†‚°á‚£æ‚†Å‚¢†‚°è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚£∑‚†ú‚£©‚£•‚£§‚£à‚†õ‚¢ø‚£∑‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†ª‚£ß‚†Ä‚¢ª‚°ü‚†≥‚£§‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢ø‚°Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚£º‚†É‚£†‚°æ‚†ã‚†à‚¢ø‚£∑‚†ò‚°á‚£ß‚†Ä‚£º‚¢†‚£ø‚£ß‚°ø‚†Ä‚£æ‚†É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚¢†‚°æ‚†ó‚†ã‚†Å‚†Ä‚†Ä‚†â‚†≥‚°Ä‚†ô‚¢ø‚£∑‚£Ñ‚†Ä‚†Ä‚†Ä‚†π‚£ß‚°Ä‚¢ª‚°Ñ‚†Ä‚†â‚†ì‚¢¶‚£Ñ‚£Ä‚°Ä‚†à‚†ª‚¢¶‚£Ñ‚°¥‚†û‚£°‚°¥‚†ã‚†Ä‚†Ä‚¢†‚†Ω‚†ª‚†Ä‚†á‚¢ª‚£§‚£ü‚°ø‚£π‚£ø‚†É‚£∏‚†è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚¢Ä‚°§‚†ö‚†â‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚¢≤‚°à‚¢ª‚£ø‚£Ü‚†Ä‚†Ä‚†Ä‚†ò‚¢∑‚°Ñ‚¢ª‚°Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚†ô‚£ø‚°∂‚¢§‚£Ä‚£§‚†û‚¢π‚°á‚†Ä‚†Ä‚†Ä‚†ò‚£ª‚†ü‚†â‚¢π‚†õ‚°ø‚†ã‚¢†‚£ø‚†è‚¢†‚°ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†â‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢ø‚°Ä‚¢ô‚£ø‚£Ñ‚£Ä‚†Ä‚†Ä‚†à‚†ª‚£Ñ‚†ª‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚£∞‚†ã‚†Ä‚†Ä‚†Ä‚¢Ä‚£¥‚†ü‚£ª‚°Ñ‚†Ä‚†Ä‚†Ä‚†∑‚†∂‚£∂‚£≤‚†í‚¢ª‚£†‚°ø‚†ã‚¢†‚°ü‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚°¥
‚£ì‚¢¶‚£Ä‚£Ä‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†π‚£Ü‚†ê‚£Ä‚°â‚°â‚†ë‚†Ä‚†Ä‚†à‚†≥‚£ù‚£∑‚£Ä‚£Ä‚£Ä‚£ì‚°Ä‚†Ä‚†§‚†æ‚†õ‚†Å‚¢Ä‚°ü‚£∑‚†Ä‚†à‚†Ä‚£ñ‚£æ‚†ü‚£ø‚£¶‚†à‚°ü‚†Ä‚†Ä‚†ö‚†Ä‚†Ä‚†Ä‚¢Ä‚°Ä‚¢Ä‚£Ä‚°¥‚¢Æ‚£Å‚†Ä
‚†â‚†≥‚£Ä‚†â‚†ô‚†≤‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚°á‚†Ä‚†à‚†£‚°à‚†ª‚£ø‚£Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚†≥‚¢ø‚£ç‚£°‚†§‚¢§‚°Ä‚†Ä‚†Ä‚†Ä‚¢†‚°æ‚†Å‚†∏‚°á‚†Ä‚†Ä‚£ø‚°ø‚£ø‚£Ω‚¢Å‚°º‚¢ß‚°Ä‚†Ä‚†Ä‚£Ä‚†¥‚†ä‚£°‚¢∂‚†ü‚†Å‚†Ä‚†Ä‚†à‚†õ
‚†Ä‚†Ä‚†à‚¢∑‚°æ‚†õ‚†â‚°ç‚†ô‚¢Ü‚†Ä‚†Ä‚†Ä‚¢†‚†á‚†Ä‚†Ä‚†Ä‚†ô‚¢¶‚°à‚†ø‚£ø‚£Ñ‚°Ä‚†Ä‚¢Ä‚°§‚†æ‚†ã‚†Ä‚£Ñ‚†Ä‚†ô‚¢∂‚°í‚†æ‚†ã‚†Ä‚†Ä‚†Ä‚°á‚†Ä‚†Ä‚¢†‚¢É‚£ø‚°Ω‚†ã‚†Ä‚†Ä‚¢ª‚†Ä‚¢ö‚°•‚£æ‚£ø‚£¥‚°ã‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚†õ‚†∂‚£ß‚†Ä‚†ò‚°∑‚¢∂‚£∂‚£º‚£§‚£§‚°Ä‚†Ä‚†Ä‚†Ä‚†±‚£§‚£∏‚†ø‚†ø‚†õ‚†â‚†Ä‚†Ä‚£†‚†æ‚†Ω‚†∑‚¢¶‚£Ä‚†ô‚°Ü‚†Ä‚†Ä‚†Ä‚†Ä‚£á‚£¥‚£∂‚¢è‚£æ‚†ü‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚†û‚£ø‚£ø‚†ü‚°è‚†â‚°ø‚£∑‚£¶‚£Ñ‚£Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£º‚†É‚†Ä‚†Ä‚°á‚¢∏‚†õ‚°á‚†∏‚¢ª‚†â‚°∑‚†ñ‚†í‚†ö‚†â‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†º‚†É‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚†â‚†â‚†ì‚†∫‚†∂‚†¶‚£ø‚°ü‚¢°‚°û‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚†Ä‚°á‚£æ‚°Ñ‚†á‚†Ä‚°á‚†Ä‚†ù‚†ø‚£æ‚£ø‚°ó
‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚°æ‚†Å‚†Ä‚†Ä‚¢Ä‚°á‚¢∏‚†Ä‚°¨‚¢§‚†à‚°Ñ‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚†â‚†â‚†â‚†â‚†ô‚†í‚†í‚†í‚†í‚†í‚¢õ‚£∂‚†ã‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚†Ä‚°á‚°ø‚£Ñ‚£Ω‚°†‚°á‚†Ä‚°Ü‚°û‚£õ‚†Å‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£∏‚¢Å‚°á‚°∏‚¢Å‚£è‚°º‚†Ä‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†§‚†Ñ‚°Ä‚†Ä‚†Ä‚†â‚†â‚†â‚†ô‚†í‚†í‚†í‚¢í‚£í‚£í‚°∂‚£∂‚£ä‚°á‚¢Ä‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†∏‚°Ü‚£á‚°ø‚£ø‚£ø‚£á‚£ß‚£æ‚£∑‚°ù‚¢∂‚†Ä‚†Ä
If you're a young 'paster', you should at least mention the source you pasted from :)
In your case: @KangelPlugins 
'''




import random
import requests
import xml.etree.ElementTree as ET
import threading
import random
import os
import time
import concurrent.futures
from ui.settings import Header, Switch, Divider, Input, Selector, Text
from base_plugin import BasePlugin, HookResult, HookStrategy
from client_utils import send_message, get_send_messages_helper
from android_utils import log
from org.telegram.messenger import ApplicationLoader
from markdown_utils import parse_markdown
from ui.bulletin import BulletinHelper
from typing import List, Dict, Tuple
from bs4 import BeautifulSoup
import json
import uuid
import mimetypes

__id__ = "rule34_search"
__name__ = "BooruSearch"
__version__ = "1.7.0"
__description__ = "–ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ Rule34, Yande.re, Danbooru. [.r34, .yandere, .danbooru]"
__author__ = "@ArThirtyFour | @KangelPlugins"
__min_version__ = "11.12.1"
__icon__ = "Sayanoutaaaa/7"

class Locales:
    default = {
        "tags_in_header": "Tags (include)",
        "tags_in_text": "Tags",
        "tags_in_subtext": 'Enter through space. Example: tag1 tag2. Leave " " for empty.',
        "tags_ex_header": "Tags (exclude)",
        "tags_ex_text": "Tags",
        "tags_ex_subtext": 'Enter through ;. Example: tag1; tag2. Leave " " for empty.',
        "antiai_text": "Anti-AI",
        "antiai_subtext": "AI-generated content filter",
        "usage_divider": "Usage: .r34.",
        "not_found": "Nothing found!",
        "not_found_filtered": "Nothing found after filtering!",
        "request_error": "Request error: {e}",
        "xml_parse_error": "XML parse error.",
        "general_data_error": "An general error occurred while fetching data: {e}",
        "unknown_site": "Unknown search site.",
        "no_args": "No arguments!",
        "usage": "Usage: .r34 [tag]\nExample: .r34 anime",
        "searching": "Searching...",
        "unexpected_url_error": "An unexpected error occurred while getting the URL.",
        "settings_output_header": "Output Display Settings",
        "show_requested_tags_text": "Show requested tags",
        "show_requested_tags_subtext": "Show tags you entered in the query",
        "show_post_tags_text": "Show tags in post",
        "show_post_tags_subtext": "Show all tags of the found post",
        "show_image_link_text": "Show image link",
        "show_image_link_subtext": "Show direct link to the image",
        "post_found_header": "üîû *Post found!*\n\n",
        "requested_tags_line": "üîç *Requested tags:* `{requested_tags_str}`\n\n",
        "post_tags_line": "üè∑Ô∏è *Tags in post:* `{post_tags}`\n\n",
        "rating_line": "üîû *Rating:* `{rating}`\n\n",
        "image_link_line": "üîó *Link:* [Open image]({image_url})",
        "search_thread_error": "An error occurred in the search thread: {e}",
        "posts_count_header": "Posts Count",
        "posts_count_text": "Number of posts to search",
        "posts_count_subtext": "Max: 1000",
        "theme_header": "Theme",
        "theme_text": "Choose caption theme",
        "theme_item_normal": "Normal",
        "theme_item_nso": "Needy Streamer Overload",
        "emoji_header_normal": "[‚ù§Ô∏è](5278611606756942667)",
        "emoji_req_normal": "[üîç](5276395476646653290)",
        "emoji_tags_normal": "[üìö](5206626000665868017)",
        "emoji_link_normal": "[üîó](5278305362703835500)",
        "emoji_header_nso": "[‚ù§Ô∏è](5366601141461205169)",
        "emoji_req_nso": "[üåê](5264949504766921879)",
        "emoji_tags_nso": "[üîÇ](5264951944308343923)",
        "emoji_link_nso": "[üìù](5267392860122006833)",
        "proxy_settings_header": "Proxy Settings",
        "use_proxy_text": "Use proxy",
        "use_proxy_subtext": "Automatically use proxy if site is blocked",
        "update_proxies_text": "Update proxy list",
        "update_proxies_subtext": "Download and check fresh proxy list",
        "proxy_update_started": "Proxy update started...",
        "show_requested_tags_text": "Show requested tags",
        "show_requested_tags_subtext": "Show tags you entered in the query",
        "show_post_tags_text": "Show tags in post",
        "show_post_tags_subtext": "Show all tags of the found post",
        "show_image_link_text": "Show image link",
        "show_image_link_subtext": "Show direct link to the image",
        "settings_output_header": "Output Display Settings",
        "send_count_header": "Send Count",
        "send_count_text": "How many posts to send",
        "send_count_subtext": "Max: 10. Can also be set at the end of the command, e.g. .r34 anime 2",
        "yandere_header": "Yande.re Settings",
        "yandere_tags_in_header": "Yande.re Tags (include)",
        "yandere_tags_in_text": "Tags",
        "yandere_tags_in_subtext": 'Enter through space. Example: tag1 tag2. Leave " " for empty.',
        "yandere_tags_ex_header": "Yande.re Tags (exclude)",
        "yandere_tags_ex_text": "Tags",
        "yandere_tags_ex_subtext": 'Enter through ;. Example: tag1; tag2. Leave " " for empty.',
        "yandere_posts_count_header": "Yande.re Posts Count",
        "yandere_posts_count_text": "Number of posts to search",
        "yandere_posts_count_subtext": "Max: 200",
        "yandere_send_count_header": "Yande.re Send Count",
        "yandere_send_count_text": "How many posts to send",
        "yandere_send_count_subtext": "Max: 10. Can be set at the end of the command",
        "yandere_rating_header": "Yande.re Rating Filter",
        "yandere_rating_text": "Rating",
        "yandere_rating_subtext": "Options: safe, questionable, explicit. Leave empty for all",
        "danbooru_header": "Danbooru Settings",
        "danbooru_tags_in_header": "Danbooru Tags (include)",
        "danbooru_tags_in_text": "Tags",
        "danbooru_tags_in_subtext": 'Enter through space. Example: tag1 tag2. Leave " " for empty.',
        "danbooru_tags_ex_header": "Danbooru Tags (exclude)",
        "danbooru_tags_ex_text": "Tags",
        "danbooru_tags_ex_subtext": 'Enter through ;. Example: tag1; tag2. Leave " " for empty.',
        "danbooru_posts_count_header": "Danbooru Posts Count",
        "danbooru_posts_count_text": "Number of posts to search",
        "danbooru_posts_count_subtext": "Max: 200",
        "danbooru_send_count_header": "Danbooru Send Count",
        "danbooru_send_count_text": "How many posts to send",
        "danbooru_send_count_subtext": "Max: 10. Can be set at the end of the command",
        "danbooru_rating_header": "Danbooru Rating Filter",
        "danbooru_rating_text": "Rating",
        "danbooru_rating_subtext": "Options: general, sensitive, questionable, explicit. Leave empty for all",
    }
    en = default
    ru = {
        "tags_in_header": "–¢–µ–≥–∏ (–≤–∫–ª—é—á–∞—é—â–∏–µ)",
        "tags_in_text": "–¢–µ–≥–∏",
        "tags_in_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª. –ü—Ä–∏–º–µ—Ä: tag1 tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "tags_ex_header": "–¢–µ–≥–∏ (–∏—Å–∫–ª—é—á–∞—é—â–∏–µ)",
        "tags_ex_text": "–¢–µ–≥–∏",
        "tags_ex_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ ;. –ü—Ä–∏–º–µ—Ä: tag1; tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "antiai_text": "–ê–Ω—Ç–∏-–ò–ò",
        "antiai_subtext": "–§–∏–ª—å—Ç—Ä —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ò–ò –∫–æ–Ω—Ç–µ–Ω—Ç–∞",
        "usage_divider": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: .r34.",
        "not_found": "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!",
        "not_found_filtered": "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏!",
        "request_error": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}",
        "xml_parse_error": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ XML.",
        "general_data_error": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}",
        "unknown_site": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–∞–π—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞.",
        "no_args": "–ù–µ—Ç –∞–≥—Ä—É–º–µ–Ω—Ç–æ–≤!",
        "usage": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: .r34 [—Ç–µ–≥–∏] [–∫–æ–ª-–≤–æ] [-–∏—Å–∫–ª—é—á–µ–Ω–∏–µ]\n–ü—Ä–∏–º–µ—Ä: .r34 anime 2 -ai_generated",
        "searching": "–ò—â–µ–º...",
        "unexpected_url_error": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ URL.",
        "post_found_header": "üîû *–ù–∞–π–¥–µ–Ω –ø–æ—Å—Ç!*\n\n",
        "requested_tags_line": "üîç *–ó–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ —Ç–µ–≥–∏:* `{requested_tags_str}`\n\n",
        "post_tags_line": "üè∑Ô∏è *–¢–µ–≥–∏ –≤ –ø–æ—Å—Ç–µ:* `{post_tags}`\n\n",
        "rating_line": "üîû *–†–µ–π—Ç–∏–Ω–≥:* `{rating}`\n\n",
        "image_link_line": "üîó *–°—Å—ã–ª–∫–∞:* [–û—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ]({image_url})",
        "search_thread_error": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –ø–æ–∏—Å–∫–∞: {e}",
        "posts_count_header": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤",
        "posts_count_text": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞",
        "posts_count_subtext": "–ú–∞–∫—Å–∏–º—É–º: 1000",
        "send_count_header": "–°–∫–æ–ª—å–∫–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å",
        "send_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å",
        "send_count_subtext": "–ú–∞–∫—Å–∏–º—É–º: 10. –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –≤ –∫–æ–Ω—Ü–µ –∫–æ–º–∞–Ω–¥—ã, –Ω–∞–ø—Ä. .r34 anime 2",
        "theme_header": "–¢–µ–º–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è",
        "theme_text": "–í—ã–±–æ—Ä —Ç–µ–º—ã –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –ø–æ–¥–ø–∏—Å–∏",
        "theme_item_normal": "–û–±—ã—á–Ω–∞—è",
        "theme_item_nso": "Needy Streamer Overload",
        "emoji_header_normal": "[‚ù§Ô∏è](5278611606756942667)",
        "emoji_req_normal": "[üîç](5276395476646653290)",
        "emoji_tags_normal": "[üìö](5206626000665868017)",
        "emoji_link_normal": "[üîó](5278305362703835500)",
        "emoji_header_nso": "[‚ù§Ô∏è](5366601141461205169)",
        "emoji_req_nso": "[üåê](5264949504766921879)",
        "emoji_tags_nso": "[üîÇ](5264951944308343923)",
        "emoji_link_nso": "[üìù](5267392860122006833)",
        "proxy_settings_header": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∫—Å–∏",
        "use_proxy_text": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ–∫—Å–∏",
        "use_proxy_subtext": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ–∫—Å–∏ –µ—Å–ª–∏ —Å–∞–π—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω",
        "update_proxies_text": "–û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏",
        "update_proxies_subtext": "–ó–∞–≥—Ä—É–∑–∏—Ç—å –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–≤–µ–∂–∏–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏",
        "proxy_update_started": "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–∞—á–∞–ª–æ—Å—å...",
        "show_requested_tags_text": "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ —Ç–µ–≥–∏",
        "show_requested_tags_subtext": "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–µ–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –≤–≤–µ–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ",
        "show_post_tags_text": "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–µ–≥–∏ –≤ –ø–æ—Å—Ç–µ",
        "show_post_tags_subtext": "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –≤—Å–µ —Ç–µ–≥–∏ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –ø–æ—Å—Ç–∞",
        "show_image_link_text": "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
        "show_image_link_subtext": "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
        "settings_output_header": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞",
        "proxy_update_success": "–°–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ –æ–±–Ω–æ–≤–ª–µ–Ω! –ù–∞–π–¥–µ–Ω–æ {count} —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏",
        "proxy_update_error": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ–∫—Å–∏: {error}",
        "no_working_proxies": "–†–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã",
        "yandere_header": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ Yande.re",
        "yandere_tags_in_header": "Yande.re —Ç–µ–≥–∏ (–≤–∫–ª—é—á–∞—é—â–∏–µ)",
        "yandere_tags_in_text": "–¢–µ–≥–∏",
        "yandere_tags_in_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª. –ü—Ä–∏–º–µ—Ä: tag1 tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "yandere_tags_ex_header": "Yande.re —Ç–µ–≥–∏ (–∏—Å–∫–ª—é—á–∞—é—â–∏–µ)",
        "yandere_tags_ex_text": "–¢–µ–≥–∏",
        "yandere_tags_ex_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ ;. –ü—Ä–∏–º–µ—Ä: tag1; tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "yandere_posts_count_header": "Yande.re –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤",
        "yandere_posts_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –∏—Å–∫–∞—Ç—å",
        "yandere_posts_count_subtext": "–ú–∞–∫—Å: 200",
        "yandere_send_count_header": "Yande.re —Å–∫–æ–ª—å–∫–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å",
        "yandere_send_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å",
        "yandere_send_count_subtext": "–ú–∞–∫—Å: 10. –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –≤ –∫–æ–Ω—Ü–µ –∫–æ–º–∞–Ω–¥—ã",
        "yandere_rating_header": "Yande.re —Ñ–∏–ª—å—Ç—Ä —Ä–µ–π—Ç–∏–Ω–≥–∞",
        "yandere_rating_text": "–†–µ–π—Ç–∏–Ω–≥",
        "yandere_rating_subtext": "–í–∞—Ä–∏–∞–Ω—Ç—ã: safe, questionable, explicit. –ü—É—Å—Ç–æ = –≤—Å–µ",
        "danbooru_header": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ Danbooru",
        "danbooru_tags_in_header": "Danbooru —Ç–µ–≥–∏ (–≤–∫–ª—é—á–∞—é—â–∏–µ)",
        "danbooru_tags_in_text": "–¢–µ–≥–∏",
        "danbooru_tags_in_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª. –ü—Ä–∏–º–µ—Ä: tag1 tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "danbooru_tags_ex_header": "Danbooru —Ç–µ–≥–∏ (–∏—Å–∫–ª—é—á–∞—é—â–∏–µ)",
        "danbooru_tags_ex_text": "–¢–µ–≥–∏",
        "danbooru_tags_ex_subtext": '–í–≤–µ–¥–∏—Ç–µ —á–µ—Ä–µ–∑ ;. –ü—Ä–∏–º–µ—Ä: tag1; tag2. –û—Å—Ç–∞–≤—å—Ç–µ " " –¥–ª—è –ø—É—Å—Ç—ã—Ö.',
        "danbooru_posts_count_header": "Danbooru –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤",
        "danbooru_posts_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –∏—Å–∫–∞—Ç—å",
        "danbooru_posts_count_subtext": "–ú–∞–∫—Å: 200",
        "danbooru_send_count_header": "Danbooru —Å–∫–æ–ª—å–∫–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å",
        "danbooru_send_count_text": "–°–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å",
        "danbooru_send_count_subtext": "–ú–∞–∫—Å: 10. –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –≤ –∫–æ–Ω—Ü–µ –∫–æ–º–∞–Ω–¥—ã",
        "danbooru_rating_header": "Danbooru —Ñ–∏–ª—å—Ç—Ä —Ä–µ–π—Ç–∏–Ω–≥–∞",
        "danbooru_rating_text": "–†–µ–π—Ç–∏–Ω–≥",
        "danbooru_rating_subtext": "–í–∞—Ä–∏–∞–Ω—Ç—ã: general, sensitive, questionable, explicit. –ü—É—Å—Ç–æ = –≤—Å–µ",
    }

def localise(key: str) -> str:
    from java.util import Locale
    lang = Locale.getDefault().getLanguage()
    locale_dict = getattr(Locales, lang, Locales.default)
    return locale_dict.get(key, key)

def localise_rating(rating_code: str, source: str = 'yandere') -> str:
    try:
        from java.util import Locale
        lang = Locale.getDefault().getLanguage()
    except Exception:
        lang = "ru"
    
    if source == 'yandere':
        if lang.startswith("ru"):
            rating_map = {'s': '–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π', 'q': '–°–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã–π', 'e': '–û—Ç–∫—Ä–æ–≤–µ–Ω–Ω—ã–π'}
        else:
            rating_map = {'s': 'Safe', 'q': 'Questionable', 'e': 'Explicit'}
    else:
        if lang.startswith("ru"):
            rating_map = {'g': '–û–±—â–∏–π', 's': '–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π', 'q': '–°–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã–π', 'e': '–û—Ç–∫—Ä–æ–≤–µ–Ω–Ω—ã–π'}
        else:
            rating_map = {'g': 'General', 's': 'Sensitive', 'q': 'Questionable', 'e': 'Explicit'}
    
    return rating_map.get(rating_code, rating_code)




def get_proxy_list_from_url(url: str) -> List[str]:
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        raw_proxies = [line.strip() for line in response.text.split('\n') if line.strip()]
        
        proxies = []
        for proxy in raw_proxies:
            if proxy.startswith('http://') or proxy.startswith('https://'):
                proxy = proxy.replace('http://', '').replace('https://', '')
            elif proxy.startswith('socks4://') or proxy.startswith('socks5://'):
                proxy = proxy.replace('socks4://', '').replace('socks5://', '')
            
            if ':' in proxy:
                proxies.append(proxy)
        
        log(f"[BooruSearch] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(proxies)} –ø—Ä–æ–∫—Å–∏")
        return proxies
    except Exception as e:
        log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–∫—Å–∏: {e}")
        return []

def check_single_proxy(proxy: str) -> Tuple[str, bool, float]:
    start_time = time.time()
    
    try:
        if ':' in proxy:
            if len(proxy.split(':')) == 2:
                proxy_dict = {
                    "http": f"http://{proxy}",
                    "https": f"http://{proxy}"
                }
            elif len(proxy.split(':')) == 4:
                parts = proxy.split(':')
                proxy_dict = {
                    "http": f"http://{parts[2]}:{parts[3]}@{parts[0]}:{parts[1]}",
                    "https": f"http://{parts[2]}:{parts[3]}@{parts[0]}:{parts[1]}"
                }
            else:
                return proxy, False, 0
        else:
            return proxy, False, 0
        
        response = requests.get(
            "https://yande.re",
            proxies=proxy_dict,
            timeout=3
        )
        
        if response.status_code == 200:
            response_time = time.time() - start_time
            return proxy, True, response_time
        else:
            return proxy, False, 0
            
    except Exception as e:
        return proxy, False, 0

def check_proxies_parallel(proxies: List[str], max_workers: int = 50, max_working: int = 20) -> List[Dict]:
    working_proxies = []
    working_proxies_lock = threading.Lock()
    stop_search = threading.Event()
    
    log(f"[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É {len(proxies)} –ø—Ä–æ–∫—Å–∏ —Å {max_workers} –ø–æ—Ç–æ–∫–∞–º–∏...")
    
    def check_proxy_wrapper(proxy):
        if stop_search.is_set():
            return proxy, False, 0
            
        proxy, is_working, response_time = check_single_proxy(proxy)
        
        if is_working:
            with working_proxies_lock:
                working_proxies.append({
                    "proxy": proxy,
                    "response_time": response_time
                })
                log(f"[BooruSearch] ‚úÖ –†–∞–±–æ—á–∏–π –ø—Ä–æ–∫—Å–∏: {proxy} (–≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {response_time:.2f}—Å)")
                
                if len(working_proxies) >= max_working:
                    stop_search.set()
                    log(f"[BooruSearch] üéØ –ù–∞–π–¥–µ–Ω–æ {max_working} —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏! –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–∏—Å–∫...")
        
        return proxy, is_working, response_time
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_proxy = {executor.submit(check_proxy_wrapper, proxy): proxy for proxy in proxies}
        
        completed = 0
        for future in concurrent.futures.as_completed(future_to_proxy):
            completed += 1
            
            if stop_search.is_set():
                for f in future_to_proxy:
                    f.cancel()
                break
            
            if completed % 100 == 0:
                with working_proxies_lock:
                    log(f"[BooruSearch] –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: {completed}/{len(proxies)} –ø—Ä–æ–∫—Å–∏ (–Ω–∞–π–¥–µ–Ω–æ —Ä–∞–±–æ—á–∏—Ö: {len(working_proxies)})")
    
    return working_proxies

def save_working_proxies_to_file(working_proxies: List[Dict], filename: str = "rule34_proxies.json"):
    try:
        data_dir = ApplicationLoader.getFilesDirFixed()
        file_path = os.path.join(str(data_dir), filename)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(working_proxies, f, ensure_ascii=False, indent=2)
        
        log(f"[BooruSearch] –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(working_proxies)} —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏ –≤ {file_path}")
    except Exception as e:
        log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")

def load_working_proxies_from_file(filename: str = "rule34_proxies.json") -> List[Dict]:
    try:
        data_dir = ApplicationLoader.getFilesDirFixed()
        file_path = os.path.join(str(data_dir), filename)
        
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                working_proxies = json.load(f)
            log(f"[BooruSearch] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(working_proxies)} –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ñ–∞–π–ª–∞")
            return working_proxies
        else:
            log(f"[BooruSearch] –§–∞–π–ª —Å –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return []
    except Exception as e:
        log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ —Å –ø—Ä–æ–∫—Å–∏: {e}")
        return []

def get_working_proxy(test_url: str = "https://api.rule34.xxx/") -> dict:
    try:
        working_proxies = load_working_proxies_from_file()
        
        if working_proxies:
            random.shuffle(working_proxies)
            
            for proxy_info in working_proxies[:5]:
                proxy = proxy_info['proxy']
                proxy_dict = {"http": f"http://{proxy}", "https": f"http://{proxy}"}
                
                try:
                    test_response = requests.get(test_url, proxies=proxy_dict, timeout=5)
                    if test_response.status_code == 200:
                        log(f"[BooruSearch] –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–±–æ—á–∏–π –ø—Ä–æ–∫—Å–∏: {proxy}")
                        return proxy_dict
                except Exception:
                    continue
        
        log("[BooruSearch] –†–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return None
        
    except Exception as e:
        log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–æ–∫—Å–∏: {e}")
        return None


class BooruSearch(BasePlugin):
    def __init__(self):
        super().__init__()
        self._cache = {}
        self._cache_expiry = {}

    def on_plugin_load(self):
        self.add_on_send_message_hook()
        log("rule34_search plugin loaded")
        try:
            if self.get_setting("use_proxy", True):
                data_dir = ApplicationLoader.getFilesDirFixed()
                file_path = os.path.join(str(data_dir), "rule34_proxies.json")
                if not os.path.exists(file_path):
                    log("[BooruSearch] –ù–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø—Ä–æ–∫—Å–∏, –∑–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤–∏—á–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ")
                    self.update_proxy_list()
        except Exception as e:
            log(f"[BooruSearch] init proxies check error: {e}")

    def on_plugin_unload(self):
        log("rule34_search plugin unloaded")

    def create_settings(self):
        settings = [
            Divider(),
            Header(text=localise("tags_in_header")),
            Input(
                key="tags_in",
                text=localise("tags_in_text"),
                default="",
                subtext=localise("tags_in_subtext"),
                icon="msg_folders_read"
            ),
            Header(text=localise("tags_ex_header")),
            Input(
                key="tags_ex",
                text=localise("tags_ex_text"),
                default="ai_generated",
                subtext=localise("tags_ex_subtext"),
                icon="msg_panel_clear"
            ),
            Divider(),
        ]
        display_options = [
            ("antiai", localise("antiai_text"), localise("antiai_subtext")),
        ]
        for key, text, subtext in display_options:
            settings.append(Switch(key=key, text=text, default=True, subtext=subtext, icon="msg_photo_settings"))
        settings.append(Divider(text=localise("usage_divider")))

        settings.append(Header(text=localise("theme_header")))
        settings.append(Selector(
            key="theme_style",
            text=localise("theme_text"),
            icon="msg2_permissions",
            default=0,
            items=[localise("theme_item_normal"), localise("theme_item_nso")]
        ))
        settings.append(Divider())

        settings.append(Header(text=localise("settings_output_header")))
        settings.append(Switch(
            key="show_requested_tags",
            text=localise("show_requested_tags_text"),
            default=True,
            subtext=localise("show_requested_tags_subtext"),
            icon="msg_reorder"
        ))
        settings.append(Switch(
            key="show_post_tags",
            text=localise("show_post_tags_text"),
            default=True,
            subtext=localise("show_post_tags_subtext"),
            icon="files_storage"
        ))
        settings.append(Switch(
            key="show_image_link",
            text=localise("show_image_link_text"),
            default=True,
            subtext=localise("show_image_link_subtext"),
            icon="msg_stories_link"
        ))
        settings.append(Divider())

        settings.append(Header(text=localise("posts_count_header")))
        settings.append(Input(
            key="posts_count",
            text=localise("posts_count_text"),
            default="100",
            subtext=localise("posts_count_subtext"),
            icon="msg_views"
        ))
        settings.append(Header(text=localise("send_count_header")))
        settings.append(Input(
            key="send_count",
            text=localise("send_count_text"),
            default="1",
            subtext=localise("send_count_subtext"),
            icon="filled_button_share"
        ))
        settings.append(Divider())

        settings.append(Header(text=localise("proxy_settings_header")))
        settings.append(Switch(
            key="use_proxy",
            text=localise("use_proxy_text"),
            default=True,
            subtext=localise("use_proxy_subtext"),
            icon="msg_stories_link"
        ))
        settings.append(Text(
            text=localise("update_proxies_text"), 
            accent=True, 
            on_click=lambda v: self.update_proxy_list(),
            icon="msg_info"
        ))
        settings.append(Divider())
        
        # Yande.re settings
        settings.append(Header(text=localise("yandere_header")))
        settings.append(Header(text=localise("yandere_tags_in_header")))
        settings.append(Input(
            key="yandere_tags_in",
            text=localise("yandere_tags_in_text"),
            default="",
            subtext=localise("yandere_tags_in_subtext"),
            icon="msg_folders_read"
        ))
        settings.append(Header(text=localise("yandere_tags_ex_header")))
        settings.append(Input(
            key="yandere_tags_ex",
            text=localise("yandere_tags_ex_text"),
            default="",
            subtext=localise("yandere_tags_ex_subtext"),
            icon="msg_panel_clear"
        ))
        settings.append(Header(text=localise("yandere_posts_count_header")))
        settings.append(Input(
            key="yandere_posts_count",
            text=localise("yandere_posts_count_text"),
            default="100",
            subtext=localise("yandere_posts_count_subtext"),
            icon="msg_views"
        ))
        settings.append(Header(text=localise("yandere_send_count_header")))
        settings.append(Input(
            key="yandere_send_count",
            text=localise("yandere_send_count_text"),
            default="1",
            subtext=localise("yandere_send_count_subtext"),
            icon="filled_button_share"
        ))
        settings.append(Header(text=localise("yandere_rating_header")))
        settings.append(Input(
            key="yandere_rating",
            text=localise("yandere_rating_text"),
            default="",
            subtext=localise("yandere_rating_subtext"),
            icon="msg_photo_settings"
        ))
        settings.append(Divider())
        
        # Danbooru settings
        settings.append(Header(text=localise("danbooru_header")))
        settings.append(Header(text=localise("danbooru_tags_in_header")))
        settings.append(Input(
            key="danbooru_tags_in",
            text=localise("danbooru_tags_in_text"),
            default="",
            subtext=localise("danbooru_tags_in_subtext"),
            icon="msg_folders_read"
        ))
        settings.append(Header(text=localise("danbooru_tags_ex_header")))
        settings.append(Input(
            key="danbooru_tags_ex",
            text=localise("danbooru_tags_ex_text"),
            default="",
            subtext=localise("danbooru_tags_ex_subtext"),
            icon="msg_panel_clear"
        ))
        settings.append(Header(text=localise("danbooru_posts_count_header")))
        settings.append(Input(
            key="danbooru_posts_count",
            text=localise("danbooru_posts_count_text"),
            default="100",
            subtext=localise("danbooru_posts_count_subtext"),
            icon="msg_views"
        ))
        settings.append(Header(text=localise("danbooru_send_count_header")))
        settings.append(Input(
            key="danbooru_send_count",
            text=localise("danbooru_send_count_text"),
            default="1",
            subtext=localise("danbooru_send_count_subtext"),
            icon="filled_button_share"
        ))
        settings.append(Header(text=localise("danbooru_rating_header")))
        settings.append(Input(
            key="danbooru_rating",
            text=localise("danbooru_rating_text"),
            default="",
            subtext=localise("danbooru_rating_subtext"),
            icon="msg_photo_settings"
        ))
        settings.append(Divider())

        return settings

    def get_image(self, query):
        tags_in_setting = self.get_setting("tags_in", "")
        tags_ex_setting = self.get_setting("tags_ex", "ai_generated")
        antiai = self.get_setting("antiai", True)
        posts_count = int(self.get_setting("posts_count", "100"))
        use_proxy = self.get_setting("use_proxy", True)
        
       
        query_parts = query.split()
        include_tags = []
        exclude_tags = []
        
        for part in query_parts:
            if part.startswith('-'):
                exclude_tags.append(part[1:]) 
            else:
                include_tags.append(part)
        
        search_tags = f"{tags_in_setting} {' '.join(include_tags)}".strip()
        

        all_exclude_tags = tags_ex_setting.split("; ") + exclude_tags
        tags_ex = [tag.strip() for tag in all_exclude_tags if tag.strip()]
        
        log(f"[BooruSearch] –í–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏: {include_tags}")
        log(f"[BooruSearch] –ò—Å–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞: {exclude_tags}")
        log(f"[BooruSearch] –û–±—â–∏–µ –∏—Å–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏: {tags_ex}")

        
        if antiai:
            anti_ai_tags = ['-ai_generated', '-stable_diffusion', '-midjourney', '-artificial_intelligence', '-neural_network', '-machine_learning', '-deepfake', '-ai_art', '-ai-generated', '-generated_by_ai', '-dall_e', '-dalle', '-novelai', '-waifu_diffusion']
            search_tags += ' ' + ' '.join(anti_ai_tags)
            log(f"[BooruSearch] –î–æ–±–∞–≤–ª–µ–Ω—ã –∞–Ω—Ç–∏-–ò–ò —Ç–µ–≥–∏ –≤ –∑–∞–ø—Ä–æ—Å")
        
        
        if tags_ex:
            exclude_tags_api = ['-' + tag for tag in tags_ex]
            search_tags += ' ' + ' '.join(exclude_tags_api)
            log(f"[BooruSearch] –î–æ–±–∞–≤–ª–µ–Ω—ã –∏—Å–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏ –≤ –∑–∞–ø—Ä–æ—Å: {exclude_tags_api}")
        
        log(f"[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫. –ó–∞–ø—Ä–æ—Å: '{search_tags}', –ª–∏–º–∏—Ç: {posts_count}")
        log(f"[BooruSearch] –ò—Å–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏: {tags_ex}")
        log(f"[BooruSearch] –ê–Ω—Ç–∏-AI –≤–∫–ª—é—á–µ–Ω: {antiai}")

        try:

            log("[BooruSearch] –ü—Ä–æ–±—É–µ–º –∑–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏...")
            try:
                response = requests.get(f"https://api.rule34.xxx/index.php?page=dapi&s=post&q=index&limit={posts_count}&tags={search_tags}&api_key=d82f6db279ce94313e629e791533d456a4309dfeb528ddab6eee4b7472156f0def07ebfd3e64b9dddbf0d3b78f227ba8a5f386533ef1ccb1377d8a97481811dc&user_id=5255009", timeout=2)
                response.raise_for_status()
                log("[BooruSearch] –ó–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏ —É—Å–ø–µ—à–µ–Ω")
            except Exception as e:
                log(f"[BooruSearch] –ó–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
               
                if use_proxy:
                    log("[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–±–æ—Ä –ø—Ä–æ–∫—Å–∏...")
                    proxy_dict = get_working_proxy()
                    if proxy_dict:
                        log(f"[BooruSearch] –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏!")
                        response = requests.get(f"https://api.rule34.xxx/index.php?page=dapi&s=post&q=index&limit={posts_count}&tags={search_tags}&api_key=d82f6db279ce94313e629e791533d456a4309dfeb528ddab6eee4b7472156f0def07ebfd3e64b9dddbf0d3b78f227ba8a5f386533ef1ccb1377d8a97481811dc&user_id=5255009", proxies=proxy_dict, timeout=10)
                        response.raise_for_status()
                    else:
                        log("[BooruSearch] –†–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏")
                        response = requests.get(f"https://api.rule34.xxx/index.php?page=dapi&s=post&q=index&limit={posts_count}&tags={search_tags}&api_key=d82f6db279ce94313e629e791533d456a4309dfeb528ddab6eee4b7472156f0def07ebfd3e64b9dddbf0d3b78f227ba8a5f386533ef1ccb1377d8a97481811dc&user_id=5255009", timeout=10)
                        response.raise_for_status()
                else:
                    log("[BooruSearch] –ü—Ä–æ–∫—Å–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –µ—â–µ —Ä–∞–∑")
                    response = requests.get(f"https://api.rule34.xxx/index.php?page=dapi&s=post&q=index&limit={posts_count}&tags={search_tags}&api_key=d82f6db279ce94313e629e791533d456a4309dfeb528ddab6eee4b7472156f0def07ebfd3e64b9dddbf0d3b78f227ba8a5f386533ef1ccb1377d8a97481811dc&user_id=5255009", timeout=10)
                    response.raise_for_status()
            soup = BeautifulSoup(response.text, 'lxml')
            posts_list = []
            for post in soup.find_all('post'):
                post_data = post.attrs
                post_data['tags'] = post_data['tags'].split()
                posts_list.append(post_data)

            log(f"[BooruSearch] –ü–æ–ª—É—á–µ–Ω–æ –ø–æ—Å—Ç–æ–≤ —Å API: {len(posts_list)}")

            if not posts_list:
                log("[BooruSearch] –ü–æ—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
                return localise("not_found")

           
            filtered_posts = posts_list
            log(f"[BooruSearch] API —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–ª –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ {len(filtered_posts)} –ø–æ—Å—Ç–æ–≤")
            
            if not filtered_posts:
                log("[BooruSearch] –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø–æ—Å—Ç–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏!")
                return localise("not_found_filtered")

            random_post = random.choice(filtered_posts)
            log(f"[BooruSearch] –í—ã–±—Ä–∞–Ω —Å–ª—É—á–∞–π–Ω—ã–π –ø–æ—Å—Ç ID: {random_post.get('id', 'unknown')}")

            return random_post

        except requests.exceptions.RequestException as e:
            log(f"[BooruSearch] –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            if "SSLCertVerificationError" in str(e):
                BulletinHelper.show_error("–°–∞–π—Ç BooruSearch.xxx –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω! –í–∫–ª—é—á–∏—Ç–µ VPN.")
            else:
                BulletinHelper.show_error(localise("request_error").format(e=e))
            return None

    def get_image_yandere(self, query):
        try:
            tags_in_setting = self.get_setting("yandere_tags_in", "")
            tags_ex_setting = self.get_setting("yandere_tags_ex", "")
            posts_count = min(int(self.get_setting("yandere_posts_count", "100")), 200)  # Yande.re max: 200
            use_proxy = self.get_setting("use_proxy", True)
            rating_filter_raw = self.get_setting("yandere_rating", "")
            rating_filter = str(rating_filter_raw).strip().lower() if rating_filter_raw else ""
            log(f"[BooruSearch] Yandere rating filter raw: '{rating_filter_raw}', processed: '{rating_filter}'")

            query_parts = query.split()
            include_tags = []
            exclude_tags = []
            for part in query_parts:
                if part.startswith('-'):
                    exclude_tags.append(part[1:])
                else:
                    include_tags.append(part)

            # Build search tags with proper spacing for multi-tag search
            all_include = []
            if tags_in_setting:
                all_include.extend(tags_in_setting.split())
            all_include.extend(include_tags)
            
            search_tags = ' '.join(all_include)
            
            # Add exclude tags
            all_exclude_tags = tags_ex_setting.split("; ") + exclude_tags
            tags_ex = [tag.strip() for tag in all_exclude_tags if tag.strip()]
            if tags_ex:
                for tag in tags_ex:
                    search_tags += f' -{tag}'

            if rating_filter:
                rating_map = {'safe': 's', 'questionable': 'q', 'explicit': 'e'}
                rating_code = rating_map.get(rating_filter, rating_filter)
                search_tags += f' rating:{rating_code}'

            log(f"[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫. –ó–∞–ø—Ä–æ—Å: '{search_tags}', –ª–∏–º–∏—Ç: {posts_count}")
            log(f"[BooruSearch] –ò—Å–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏: {tags_ex}")
            try:
                log("[BooruSearch] –ü—Ä–æ–±—É–µ–º –∑–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏...")
                response = requests.get(
                    f"https://yande.re/post.json?limit={posts_count}&tags={search_tags}",
                    timeout=2
                )
                response.raise_for_status()
                log("[BooruSearch] –ó–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏ —É—Å–ø–µ—à–µ–Ω")
            except Exception as e:
                log(f"[BooruSearch] –ó–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
                if use_proxy:
                    log("[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–±–æ—Ä –ø—Ä–æ–∫—Å–∏...")
                    proxy_dict = get_working_proxy("https://yande.re/post.json?limit=1")
                    if proxy_dict:
                        log("[BooruSearch] –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏!")
                        response = requests.get(
                            f"https://yande.re/post.json?limit={posts_count}&tags={search_tags}",
                            timeout=2,
                            proxies=proxy_dict
                        )
                        response.raise_for_status()
                    else:
                        log("[BooruSearch] –†–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏")
                        response = requests.get(
                            f"https://yande.re/post.json?limit={posts_count}&tags={search_tags}",
                            timeout= 10
                        )
                        response.raise_for_status()
                else:
                    log("[BooruSearch] –ü—Ä–æ–∫—Å–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –µ—â–µ —Ä–∞–∑")
                    response = requests.get(
                        f"https://yande.re/post.json?limit={posts_count}&tags={search_tags}",
                        timeout=10
                    )
                    response.raise_for_status()

            data = response.json()
            log(f"[BooruSearch] –ü–æ–ª—É—á–µ–Ω–æ –ø–æ—Å—Ç–æ–≤ —Å API: {len(data)}")
            if not isinstance(data, list) or not data:
                log("[BooruSearch] –ü–æ—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
                return localise("not_found")

            post = random.choice(data)
            log(f"[BooruSearch] –í—ã–±—Ä–∞–Ω —Å–ª—É—á–∞–π–Ω—ã–π –ø–æ—Å—Ç ID: {post.get('id', 'unknown')}")
            # Normalize fields similar to BooruSearch
            tags = []
            try:
                if isinstance(post.get('tags'), str):
                    tags = post.get('tags', '').split()
            except Exception:
                tags = []
            image_url = post.get('jpeg_url') or post.get('sample_url') or post.get('file_url')
            if not image_url:
                return localise("not_found")
            rating = post.get('rating', 'unknown')
            rating_display = localise_rating(rating, 'yandere')

            return {
                'id': post.get('id'),
                'file_url': image_url,
                'tags': tags,
                'rating': rating_display
            }
        except requests.exceptions.RequestException as e:
            log(f"[BooruSearch] –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ Yande.re: {e}")
            if "SSLCertVerificationError" in str(e):
                BulletinHelper.show_error("–°–∞–π—Ç Yande.re –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω! –í–∫–ª—é—á–∏—Ç–µ VPN.")
            else:
                BulletinHelper.show_error(localise("request_error").format(e=e))
            return None
        except json.JSONDecodeError as e:
            log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç Yande.re: {e}")
            BulletinHelper.show_error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Yande.re")
            return None
        except Exception as e:
            log(f"[BooruSearch] –û–±—â–∞—è –æ—à–∏–±–∫–∞ Yande.re: {e}")
            BulletinHelper.show_error(localise("general_data_error").format(e=e))
            return None

    def get_image_danbooru(self, query):
        try:
            tags_in_setting = self.get_setting("danbooru_tags_in", "")
            tags_ex_setting = self.get_setting("danbooru_tags_ex", "")
            posts_count = min(int(self.get_setting("danbooru_posts_count", "100")), 200)  # Danbooru max: 200
            use_proxy = self.get_setting("use_proxy", True)
            rating_filter_raw = self.get_setting("danbooru_rating", "")
            rating_filter = str(rating_filter_raw).strip().lower() if rating_filter_raw else ""
            log(f"[BooruSearch] Danbooru rating filter raw: '{rating_filter_raw}', processed: '{rating_filter}'")

            query_parts = query.split()
            include_tags = []
            exclude_tags = []
            for part in query_parts:
                if part.startswith('-'):
                    exclude_tags.append(part[1:])
                else:
                    include_tags.append(part)

            all_include = []
            if tags_in_setting:
                all_include.extend(tags_in_setting.split())
            all_include.extend(include_tags)
            
            search_tags = ' '.join(all_include)
            all_exclude_tags = tags_ex_setting.split("; ") + exclude_tags
            tags_ex = [tag.strip() for tag in all_exclude_tags if tag.strip()]
            if tags_ex:
                for tag in tags_ex:
                    search_tags += f' -{tag}'
            
            if rating_filter:
                rating_map = {'general': 'g', 'sensitive': 's', 'questionable': 'q', 'explicit': 'e'}
                rating_code = rating_map.get(rating_filter, rating_filter)
                search_tags += f' rating:{rating_code}'

            log(f"[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫. –ó–∞–ø—Ä–æ—Å: '{search_tags}', –ª–∏–º–∏—Ç: {posts_count}")
            log(f"[BooruSearch] –ò—Å–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ–≥–∏: {tags_ex}")
            base = "https://danbooru.donmai.us/posts.json"
            params = {
                'limit': posts_count,
                'tags': search_tags,
            }

            try:
                log("[BooruSearch] –ü—Ä–æ–±—É–µ–º –∑–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏...")
                response = requests.get(base, params=params, timeout=5)
                response.raise_for_status()
                log("[BooruSearch] –ó–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏ —É—Å–ø–µ—à–µ–Ω")
            except Exception as e:
                log(f"[BooruSearch] –ó–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
                if use_proxy:
                    log("[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–±–æ—Ä –ø—Ä–æ–∫—Å–∏...")
                    proxy_dict = get_working_proxy("https://danbooru.donmai.us/posts.json?limit=1")
                    if proxy_dict:
                        log("[BooruSearch] –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏!")
                        response = requests.get(base, params=params, timeout=10, proxies=proxy_dict)
                        response.raise_for_status()
                    else:
                        log("[BooruSearch] –†–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏")
                        response = requests.get(base, params=params, timeout=10)
                        response.raise_for_status()
                else:
                    log("[BooruSearch] –ü—Ä–æ–∫—Å–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏ –µ—â–µ —Ä–∞–∑")
                    response = requests.get(base, params=params, timeout=10)
                    response.raise_for_status()

            data = response.json()
            log(f"[BooruSearch] –ü–æ–ª—É—á–µ–Ω–æ –ø–æ—Å—Ç–æ–≤ —Å API: {len(data)}")
            if not isinstance(data, list) or not data:
                log("[BooruSearch] –ü–æ—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
                return localise("not_found")

            post = random.choice(data)
            log(f"[BooruSearch] –í—ã–±—Ä–∞–Ω —Å–ª—É—á–∞–π–Ω—ã–π –ø–æ—Å—Ç ID: {post.get('id', 'unknown')}")
            tags_str = post.get('tag_string', '') or ''
            tags = tags_str.split()
            image_url = post.get('file_url') or post.get('large_file_url') or post.get('preview_file_url')
            if not image_url:
                return localise("not_found")
            
            # Get rating
            rating = post.get('rating', 'unknown')
            rating_display = localise_rating(rating, 'danbooru')

            return {
                'id': post.get('id'),
                'file_url': image_url,
                'tags': tags,
                'rating': rating_display
            }
        except Exception as e:
            log(f"[BooruSearch] –û—à–∏–±–∫–∞: {e}")
            BulletinHelper.show_error(localise("general_data_error").format(e=e))
            return None

    def on_send_message_hook(self, account, params):
        if not hasattr(params, 'message') or not isinstance(params.message, str):
            return HookResult()

        msg = params.message.strip()
        usage = localise("usage")
        try:
            if msg.startswith(".proxy_get"):
                self.update_proxy_list()
                params.message = localise("proxy_update_started")
                return HookResult(strategy=HookStrategy.CANCEL)
        except Exception as e:
            log(f"[BooruSearch] proxy_get error: {e}")

        if not (msg.startswith(".r34") or msg.startswith(".yandere") or msg.startswith(".danbooru")):
            return HookResult()

        cmd_type = ".r34"
        if msg.startswith(".yandere"):
            cmd_type = ".yandere"
            log("[BooruSearch] –ö–æ–º–∞–Ω–¥–∞ .yandere –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞")
        elif msg.startswith(".danbooru"):
            cmd_type = ".danbooru"
            log("[BooruSearch] –ö–æ–º–∞–Ω–¥–∞ .danbooru –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞")
        else:
            log("[BooruSearch] –ö–æ–º–∞–Ω–¥–∞ .r34 –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞")      

        parts = msg.split(" ", 1)
        query = ""
        if len(parts) > 1:
            query = parts[1].strip()
        send_n = 1
        try:
            if cmd_type == ".yandere":
                send_n = int(self.get_setting("yandere_send_count", "1"))
            elif cmd_type == ".danbooru":
                send_n = int(self.get_setting("danbooru_send_count", "1"))
            else:
                send_n = int(self.get_setting("send_count", "1"))
        except Exception:
            send_n = 1
        try:
            tokens = query.split()
            if tokens and tokens[-1].isdigit():
                send_n = int(tokens[-1])
                tokens = tokens[:-1]
                query = " ".join(tokens)
        except Exception:
            pass
        try:
            send_n = max(1, min(10, int(send_n)))
        except Exception:
            send_n = 1

        log(f"[BooruSearch] –ó–∞–ø—Ä–æ—Å: '{query}'")

        
        include_tags = [part for part in query.split() if not part.startswith('-')]
        if cmd_type == ".yandere":
            tags_in_setting = self.get_setting("yandere_tags_in", "").strip()
        elif cmd_type == ".danbooru":
            tags_in_setting = self.get_setting("danbooru_tags_in", "").strip()
        else:
            tags_in_setting = self.get_setting("tags_in", "nude").strip()
        
        if not include_tags and not tags_in_setting:
            if cmd_type == ".yandere":
                BulletinHelper.show_error("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: .yandere [—Ç–µ–≥–∏]\n–ü—Ä–∏–º–µ—Ä: .yandere anime 1girl")
                return HookResult(strategy=HookStrategy.CANCEL)
            elif cmd_type == ".danbooru":
                BulletinHelper.show_error("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: .danbooru [—Ç–µ–≥–∏]\n–ü—Ä–∏–º–µ—Ä: .danbooru touhou solo")
                return HookResult(strategy=HookStrategy.CANCEL)
            else:
                params.message = usage
                return HookResult(strategy=HookStrategy.MODIFY, params=params)

        def search_and_reply(search_query, peer, reply_to_msg=None, reply_to_top_msg=None, send_n: int = 1):
            log(f"[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –≤ –ø–æ—Ç–æ–∫–µ. –ó–∞–ø—Ä–æ—Å: '{search_query}', –æ—Ç–ø—Ä–∞–≤–∏–º {send_n} –ø–æ—Å—Ç(–∞)")
            for idx in range(send_n):
                try:
                    if cmd_type == ".yandere":
                        result = self.get_image_yandere(search_query)
                    elif cmd_type == ".danbooru":
                        result = self.get_image_danbooru(search_query)
                    else:
                        result = self.get_image(search_query)

                    log(f"[BooruSearch] –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ –ø–æ–ª—É—á–µ–Ω: {type(result)}")

                    if isinstance(result, dict) and result.get("file_url"):
                        log(f"[BooruSearch] –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º: {result.get('id', 'unknown')}")
                        if cmd_type == ".yandere":
                            tags_in_setting = self.get_setting("yandere_tags_in", "")
                        elif cmd_type == ".danbooru":
                            tags_in_setting = self.get_setting("danbooru_tags_in", "")
                        else:
                            tags_in_setting = self.get_setting("tags_in", "")
                        requested_tags = (tags_in_setting + (" " + query if query else "")).strip()
                        requested_tags_str = requested_tags if requested_tags else "(–ø—É—Å—Ç–æ)"
                        post_tags = ", ".join(result.get('tags', []))
                        image_url = result.get("file_url")
                        rating = result.get('rating', '') if (cmd_type == ".yandere" or cmd_type == ".danbooru") else ''
                        message_text = self._build_caption_text(requested_tags_str, post_tags, image_url, rating)

                        parsed_message = parse_markdown(message_text)
                        try:
                            ext = os.path.splitext(image_url.split('?')[0])[1].lower()
                        except Exception:
                            ext = ""
                        if ext in (".mp4", ".webm", ".gif"):
                            try:
                                send_message({
                                    "peer": peer,
                                    "message": parsed_message.text,
                                    "entities": [entity.to_tlrpc_object() for entity in parsed_message.entities],
                                    **({"replyToMsg": reply_to_msg} if reply_to_msg is not None else {}),
                                    **({"replyToTopMsg": reply_to_top_msg} if reply_to_top_msg is not None else {})
                                })
                            except Exception as se:
                                log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –≤–∏–¥–µ–æ/GIF: {se}")
                            continue
                        try:
                            local_path, is_image = self._download_media(image_url)
                        except Exception as de:
                            log(f"[BooruSearch] –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –º–µ–¥–∏–∞: {de}")
                            message_params = {
                                "peer": peer,
                                "message": parsed_message.text,
                                "entities": [entity.to_tlrpc_object() for entity in parsed_message.entities]
                            }
                            if reply_to_msg is not None:
                                message_params["replyToMsg"] = reply_to_msg
                            if reply_to_top_msg is not None:
                                message_params["replyToTopMsg"] = reply_to_top_msg
                            send_message(message_params)
                            continue

                        try:
                            if is_image:
                                helper = get_send_messages_helper()
                                photo = helper.generatePhotoSizes(local_path, None)
                                if photo is not None:
                                    send_message({
                                        "peer": peer,
                                        "photo": photo,
                                        "path": local_path,
                                        "caption": parsed_message.text,
                                        "entities": [e.to_tlrpc_object() for e in parsed_message.entities],
                                        **({"replyToMsg": reply_to_msg} if reply_to_msg is not None else {}),
                                        **({"replyToTopMsg": reply_to_top_msg} if reply_to_top_msg is not None else {})
                                    })
                                else:
                                    send_message({
                                        "peer": peer,
                                        "message": parsed_message.text,
                                        "entities": [e.to_tlrpc_object() for e in parsed_message.entities],
                                        **({"replyToMsg": reply_to_msg} if reply_to_msg is not None else {}),
                                        **({"replyToTopMsg": reply_to_top_msg} if reply_to_top_msg is not None else {})
                                    })
                            else:
                                send_message({
                                    "peer": peer,
                                    "path": local_path,
                                    **({"replyToMsg": reply_to_msg} if reply_to_msg is not None else {}),
                                    **({"replyToTopMsg": reply_to_top_msg} if reply_to_top_msg is not None else {})
                                })
                                time.sleep(0.2)
                                send_message({
                                    "peer": peer,
                                    "message": parsed_message.text,
                                    "entities": [e.to_tlrpc_object() for e in parsed_message.entities],
                                    **({"replyToMsg": reply_to_msg} if reply_to_msg is not None else {}),
                                    **({"replyToTopMsg": reply_to_top_msg} if reply_to_top_msg is not None else {})
                                })
                        except Exception as se:
                            log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –º–µ–¥–∏–∞: {se}")
                            send_message({
                                "peer": peer,
                                "message": parsed_message.text,
                                "entities": [e.to_tlrpc_object() for e in parsed_message.entities],
                                **({"replyToMsg": reply_to_msg} if reply_to_msg is not None else {}),
                                **({"replyToTopMsg": reply_to_top_msg} if reply_to_top_msg is not None else {})
                            })
                    elif isinstance(result, str):
                        log(f"[BooruSearch] –ü–æ–∫–∞–∑—ã–≤–∞–µ–º Bulletin: {result}")
                        BulletinHelper.show_error(result)
                    elif result is None:
                        log(f"[BooruSearch] –†–µ–∑—É–ª—å—Ç–∞—Ç None, –Ω–∏—á–µ–≥–æ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º")
                        pass
                    else:
                        log(f"[BooruSearch] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(result)}")
                        BulletinHelper.show_error(localise("unexpected_url_error"))

                except Exception as e:
                    log(f"[BooruSearch] –û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –ø–æ–∏—Å–∫–∞: {e}")
                    BulletinHelper.show_error(localise("search_thread_error").format(e=e))
                # small delay between sends
                time.sleep(0.3)

        try:
            BulletinHelper.show_info(localise("searching"))
        except Exception as e:
            log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∏–∞–ª–æ–≥–∞: {e}")

        log("[BooruSearch] –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –ø–æ–∏—Å–∫–∞")
        
        threading.Thread(target=lambda: search_and_reply(query, params.peer, params.replyToMsg, params.replyToTopMsg, send_n), daemon=True).start()

        params.message = localise("searching")
        return HookResult(strategy=HookStrategy.CANCEL)

    def update_proxy_list(self):
        def update_proxies_background():
            try:
                BulletinHelper.show_info(localise("proxy_update_started"))
                log("[BooruSearch] –ù–∞—á–∏–Ω–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–∫—Å–∏...")
                
                proxy_url = "https://cdn.jsdelivr.net/gh/proxifly/free-proxy-list@main/proxies/all/data.txt"
                
                all_proxies = get_proxy_list_from_url(proxy_url)
                log(f"[BooruSearch] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_proxies)} –ø—Ä–æ–∫—Å–∏ –∏–∑ {proxy_url}")
                
                if not all_proxies:
                    BulletinHelper.show_error(localise("proxy_update_error").format(error="–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–∫—Å–∏"))
                    return
                
                unique_proxies = list(set(all_proxies))
                log(f"[BooruSearch] –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏: {len(unique_proxies)}")
                
                max_proxies_to_check = 2000
                if len(unique_proxies) > max_proxies_to_check:
                    unique_proxies = unique_proxies[:max_proxies_to_check]
                    log(f"[BooruSearch] –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –¥–æ {max_proxies_to_check} –ø—Ä–æ–∫—Å–∏")
                
                working_proxies = check_proxies_parallel(unique_proxies, max_workers=100, max_working=30)
                
                if working_proxies:
                    working_proxies.sort(key=lambda x: x['response_time'])
                    
                    save_working_proxies_to_file(working_proxies)
                    
                    BulletinHelper.show_success(localise("proxy_update_success").format(count=len(working_proxies)))
                    log(f"[BooruSearch] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ù–∞–π–¥–µ–Ω–æ {len(working_proxies)} —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏")
                else:
                    BulletinHelper.show_error(localise("no_working_proxies"))
                    log("[BooruSearch] –†–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    
            except Exception as e:
                error_msg = str(e)
                BulletinHelper.show_error(localise("proxy_update_error").format(error=error_msg))
                log(f"[BooruSearch] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ–∫—Å–∏: {e}")
        
        threading.Thread(target=update_proxies_background, daemon=True).start()
    
    def _dismiss_dialog(self):
        pass

    def on_setting_changed(self, key, value):
        try:
            if key == "use_proxy" and bool(value):
                self.update_proxy_list()
        except Exception as e:
            log(f"[BooruSearch] on_setting_changed error: {e}")

    def _build_caption_text(self, requested_tags_str: str, post_tags: str, image_url: str, rating: str = '') -> str:
        try:
            from java.util import Locale as _Loc
            _lang = _Loc.getDefault().getLanguage()
        except Exception:
            _lang = "ru"

        nsfw = int(self.get_setting("theme_style", 0)) == 1

        if _lang.startswith("ru"):
            header = "*–ù–∞–π–¥–µ–Ω –ø–æ—Å—Ç!*"
            req_label = "*–ó–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ —Ç–µ–≥–∏:*"
            tags_label = "*–¢–µ–≥–∏ –≤ –ø–æ—Å—Ç–µ:*"
            link_label = "*–°—Å—ã–ª–∫–∞:*"
            open_text = "–û—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
        else:
            header = "*Post found!*"
            req_label = "*Requested tags:*"
            tags_label = "*Post tags:*"
            link_label = "*Link:*"
            open_text = "Open image"

        if nsfw:
            emo_header = localise("emoji_header_nso")
            emo_req = localise("emoji_req_nso")
            emo_tags = localise("emoji_tags_nso")
            emo_link = localise("emoji_link_nso")
        else:
            emo_header = localise("emoji_header_normal")
            emo_req = localise("emoji_req_normal")
            emo_tags = localise("emoji_tags_normal")
            emo_link = localise("emoji_link_normal")

        lines = []
        lines.append(f"{emo_header} | {header}")

        if self.get_setting("show_requested_tags", True) and requested_tags_str:
            code_req = self._md_code(requested_tags_str)
            lines.append(f"{emo_req} | {req_label} `{code_req}`")

        if self.get_setting("show_post_tags", True) and post_tags:
            code_tags = self._md_code(post_tags)
            lines.append(f"{emo_tags} | {tags_label} `{code_tags}`")
        
        if rating:
            if _lang.startswith("ru"):
                rating_label = "*–†–µ–π—Ç–∏–Ω–≥:*"
            else:
                rating_label = "*Rating:*"
            if nsfw:
                rating_emoji = "[üíî](5258354685563129815)"
            else:
                rating_emoji = "[üõ°](5276262671962892944)"
            
            lines.append(f"{rating_emoji} | {rating_label} `{rating}`")

        if self.get_setting("show_image_link", True) and image_url:
            lines.append(f"{emo_link} | {link_label} [{open_text}]({image_url})")

        return "\n".join(lines)

    def _md_code(self, s: str) -> str:
        try:
            return s.replace('`', r'\`')
        except Exception:
            return s

    def _download_media(self, url: str) -> tuple:
        try:
            ext = os.path.splitext(url.split('?')[0])[1].lower()
            is_image_ext = ext in ('.jpg', '.jpeg', '.webp','.png')
            filename = f"rule34_{uuid.uuid4().hex}{ext if ext else ''}"
            data_dir = ApplicationLoader.getFilesDirFixed()
            local_path = os.path.join(str(data_dir), filename)

            def do_request(session_proxies=None):
                with requests.get(url, stream=True, timeout=20, proxies=session_proxies) as r:
                    r.raise_for_status()
                    with open(local_path, 'wb') as f:
                        for chunk in r.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)

            try:
                do_request()
            except Exception:
                if self.get_setting("use_proxy", True):
                    proxy = get_working_proxy()
                    if proxy:
                        do_request(proxy)
                    else:
                        raise
                else:
                    raise

            if not ext:
                ctype = mimetypes.guess_type(local_path)[0] or ''
                is_image_ext = ctype.startswith('image/')

            return local_path, is_image_ext
        except Exception as e:
            raise e
